# -*- coding: utf-8 -*-
"""experiments_on_nlp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aW3ImdIBDlounInXJM8Xol2FCOZwurof
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
from pathlib import Path

# Define the file path and extraction path
file_path = '/content/drive/MyDrive/nlp_research/archive.zip'
extract_path = '/content/drive/MyDrive/nlp_research/extracted_files'

# Function to attempt extraction
def extract_zip(file_path, extract_path):
    try:
        # Create the extraction path if it doesn't exist
        Path(extract_path).mkdir(parents=True, exist_ok=True)

        # Try to open the zip file
        with zipfile.ZipFile(file_path, 'r') as zip_ref:
            # Extract all contents
            zip_ref.extractall(extract_path)
        return f"Files extracted successfully to {extract_path}"
    except zipfile.BadZipFile:
        return "Error: The file is not a zip file or it is corrupted."

# Attempt to extract the zip file
result = extract_zip(file_path, extract_path)
result

import os
import pandas as pd
import random

def extract_english_subtitles(base_path, num_movies=10):
    """
    Extract English subtitles from time-based CSV files for a random selection of movies.

    Args:
        base_path (str): Path to the base directory containing movie folders
        num_movies (int): Number of random movies to process

    Returns:
        list: Combined list of English subtitles from random movies
    """
    all_subtitles = []

    # Get list of all movie folders
    movie_folders = [f for f in os.listdir(base_path)
                    if os.path.isdir(os.path.join(base_path, f))]

    # If we have more movies than requested, randomly select subset
    if len(movie_folders) > num_movies:
        movie_folders = random.sample(movie_folders, num_movies)

    print(f"Selected {len(movie_folders)} movies for processing:")
    for folder in movie_folders:
        print(f"- {folder}")
    print()

    # Process selected movies
    for movie_folder in movie_folders:
        movie_path = os.path.join(base_path, movie_folder)
        time_based_file = os.path.join(movie_path, 'parallel_subtitle_time_based.csv')

        if os.path.exists(time_based_file):
            try:
                # Read the CSV file
                df = pd.read_csv(time_based_file)

                # Extract language_1 column (English subtitles)
                if 'language_1' in df.columns:
                    subtitles = df['language_1'].tolist()

                    # Add movie name as metadata
                    movie_subtitles = {
                        'movie': movie_folder,
                        'subtitles': subtitles
                    }

                    all_subtitles.append(movie_subtitles)
                    print(f"Successfully processed {movie_folder}")
                else:
                    print(f"Warning: No language_1 column found in {movie_folder}")

            except Exception as e:
                print(f"Error processing {movie_folder}: {str(e)}")

    return all_subtitles

def save_corpus(subtitles, output_file):
    """
    Save the combined subtitles to a text file.

    Args:
        subtitles (list): List of dictionaries containing movie names and subtitles
        output_file (str): Path to the output file
    """
    with open(output_file, 'w', encoding='utf-8') as f:
        # Write header with movie list
        f.write("=== Selected Movies ===\n")
        for i, movie_data in enumerate(subtitles, 1):
            f.write(f"{i}. {movie_data['movie']}\n")
        f.write("\n=== Subtitles ===\n")

        # Write subtitles
        for movie_data in subtitles:
            f.write(f"\n=== {movie_data['movie']} ===\n\n")
            for subtitle in movie_data['subtitles']:
                if pd.notna(subtitle):  # Check for NaN values
                    f.write(f"{subtitle}\n")

def main():
    # Configuration
    base_path = r'/content/drive/MyDrive/nlp_research/extracted_files/english to thai'
    output_file = '/content/drive/MyDrive/nlp_research/english_corpus_10movies.txt'
    num_movies = 10

    # Set random seed for reproducibility
    random.seed(42)  # You can change this number or remove it for different random selections

    # Extract subtitles
    print("Starting subtitle extraction...")
    subtitles = extract_english_subtitles(base_path, num_movies)

    # Save to file
    if subtitles:
        save_corpus(subtitles, output_file)
        print(f"\nCorpus saved to {output_file}")

        # Print statistics
        total_movies = len(subtitles)
        total_lines = sum(len(movie['subtitles']) for movie in subtitles)
        print(f"\nStatistics:")
        print(f"Total movies processed: {total_movies}")
        print(f"Total subtitle lines: {total_lines}")
    else:
        print("No subtitles were extracted")

if __name__ == "__main__":
    main()

!pip install torch torchvision torchaudio transformers numpy
!pip install --upgrade accelerate

import re
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertModel

# Step 1: Load and preprocess the corpus
with open('/content/drive/MyDrive/nlp_research/english_corpus_10movies.txt', 'r') as file:
    subtitles = file.readlines()

def clean_text(text):
    text = text.lower()
    text = re.sub(r"[^a-zA-Z0-9\s]", "", text)  # Remove punctuation
    return text

cleaned_subtitles = [clean_text(line) for line in subtitles]

# Initialize BERT tokenizer
bert_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# Tokenize sequences and labels
sequences = []
labels = []

for line in cleaned_subtitles:
    tokens = bert_tokenizer.encode(line, add_special_tokens=False)
    for i in range(2, len(tokens)):
        sequences.append(tokens[i-2:i])  # Two-word sequences
        labels.append(tokens[i])         # Next word as the label

# Step 2: Create a custom PyTorch Dataset
class TextDataset(Dataset):
    def __init__(self, sequences, labels):
        self.sequences = sequences
        self.labels = labels

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        input_ids = torch.tensor(self.sequences[idx])
        attention_mask = torch.ones_like(input_ids)  # Assuming full attention
        label = torch.tensor(self.labels[idx])
        return input_ids, attention_mask, label

dataset = TextDataset(sequences, labels)
dataloader = DataLoader(dataset, batch_size=800, shuffle=True)

from torch.optim import Adam

# Step 3: Define the enhanced model
class EnhancedNextWordPredictor(nn.Module):
    def __init__(self, bert_model, vocab_size):
        super(EnhancedNextWordPredictor, self).__init__()
        self.bert = bert_model
        self.attention = nn.MultiheadAttention(embed_dim=bert_model.config.hidden_size, num_heads=4, batch_first=True)
        self.fc = nn.Linear(bert_model.config.hidden_size, vocab_size)

    def forward(self, input_ids, attention_mask):
        bert_output = self.bert(input_ids, attention_mask=attention_mask).last_hidden_state
        attn_output, _ = self.attention(bert_output, bert_output, bert_output)
        last_token_output = attn_output[:, -1, :]  # Use the last token's output
        logits = self.fc(last_token_output)       # Predict vocab probabilities
        return logits

# Load BERT model and initialize the enhanced model
bert_model = BertModel.from_pretrained("bert-base-uncased")
vocab_size = len(bert_tokenizer.get_vocab())
model = EnhancedNextWordPredictor(bert_model, vocab_size)

# Step 4: Set up loss, optimizer, and checkpointing
criterion = nn.CrossEntropyLoss()
optimizer = Adam(model.parameters(), lr=5e-5)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Checkpoint to save the best model
best_loss = float('inf')
checkpoint_path = "/content/drive/MyDrive/nlp_research/best_model.pth"

# Training loop
for epoch in range(50):
    model.train()
    total_loss = 0
    for batch in dataloader:
        input_ids, attention_mask, targets = batch
        input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)

        optimizer.zero_grad()
        logits = model(input_ids, attention_mask)
        loss = criterion(logits, targets)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(dataloader)
    print(f"Epoch {epoch+1} completed with average loss: {avg_loss}")

    # Save the best model
    if avg_loss < best_loss:
        best_loss = avg_loss
        torch.save(model.state_dict(), checkpoint_path)
        print("Best model saved.")

# Step 5: Define a function to predict the next word
def predict_next_word(model, bert_tokenizer, input_text):
    input_text = clean_text(input_text)
    tokens = bert_tokenizer.encode(input_text, add_special_tokens=False)
    if len(tokens) < 2:
        print("Input text must contain at least two words.")
        return None
    input_sequence = torch.tensor([tokens[-2:]]).to(device)
    attention_mask = torch.ones_like(input_sequence).to(device)
    model.eval()
    with torch.no_grad():
        logits = model(input_sequence, attention_mask)
    predicted_index = torch.argmax(logits, dim=-1).item()
    predicted_word = bert_tokenizer.decode([predicted_index])
    return predicted_word

# Example usage
input_text = "what the"
next_word = predict_next_word(model, bert_tokenizer, input_text)
print(f"Next word prediction for '{input_text}': {next_word}")

!pip install ffmpeg-python openai-whisper

import ffmpeg

def extract_audio(video_path, audio_path):
    ffmpeg.input(video_path).output(audio_path).run()

# Example usage
extract_audio(r'/content/8 Mile (2002) - The Lunch Truck Scene (6_10) _ Movieclips.mp4', 'output_audio.wav')

import IPython.display as ipd
ipd.Audio('output_audio.wav')

import whisper

def transcribe_audio(audio_path):
    # Load the model
    model = whisper.load_model("medium")  # Use "base" or larger models like "medium", "large" for better accuracy

    # Transcribe the audio
    result = model.transcribe(audio_path)
    return result['text']

# Example usage
transcribed_text = transcribe_audio('output_audio.wav')
print(transcribed_text)

import whisper
from tqdm import tqdm
import librosa
import numpy as np
import torch
from typing import List, Tuple

def load_and_split_audio(audio_path: str, chunk_duration: int = 30) -> Tuple[List[np.ndarray], int]:
    """
    Load and split audio file into chunks for processing.

    Args:
        audio_path (str): Path to the audio file
        chunk_duration (int): Duration of each chunk in seconds

    Returns:
        Tuple[List[np.ndarray], int]: List of audio chunks and sample rate
    """
    try:
        # Load audio using librosa
        audio, sr = librosa.load(audio_path, sr=16000)  # Whisper expects 16kHz audio

        # Calculate number of samples per chunk
        chunk_samples = chunk_duration * sr
        total_chunks = int(np.ceil(len(audio) / chunk_samples))

        # Split audio into chunks
        chunks = []
        for i in range(total_chunks):
            start = i * chunk_samples
            end = min((i + 1) * chunk_samples, len(audio))
            chunk = audio[start:end]

            # Pad last chunk if necessary
            if len(chunk) < chunk_samples:
                chunk = np.pad(chunk, (0, chunk_samples - len(chunk)))

            chunks.append(chunk)

        return chunks, sr

    except Exception as e:
        raise Exception(f"Error loading audio file: {str(e)}")

def transcribe_audio_with_progress(audio_path: str, model_size: str = "base") -> str:
    """
    Transcribe audio file using OpenAI's Whisper model with progress bar.

    Args:
        audio_path (str): Path to the audio file
        model_size (str): Whisper model size ("tiny", "base", "small", "medium", "large")

    Returns:
        str: Transcribed text
    """
    try:
        # Load the model
        model = whisper.load_model(model_size)

        # Move model to GPU if available
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model.to(device)

        # Load and split the audio
        chunks, sr = load_and_split_audio(audio_path)

        # Initialize empty transcription
        transcription = []

        # Process each chunk with progress bar
        for chunk in tqdm(chunks, desc="Transcribing Audio"):
            # Convert chunk to Mel spectrogram
            mel = whisper.log_mel_spectrogram(chunk).to(device)

            # Decode the audio
            result = model.transcribe(chunk, language="en")
            transcription.append(result["text"].strip())

        # Join all transcriptions with proper spacing
        return " ".join(transcription)

    except Exception as e:
        raise Exception(f"Error during transcription: {str(e)}")

def main():
    """Main function to demonstrate usage"""
    try:
        audio_path = "output_audio.wav"
        transcribed_text = transcribe_audio_with_progress(audio_path, model_size="base")
        print("Transcription:")
        print(transcribed_text)

    except Exception as e:
        print(f"Error: {str(e)}")

if __name__ == "__main__":
    main()

def extract_english_subtitles(base_path, selected_movies):
    """
    Extract English subtitles from time-based CSV files for a specified list of movies.

    Args:
        base_path (str): Path to the base directory containing movie folders
        selected_movies (list): List of movie folder names to process

    Returns:
        list: Combined list of English subtitles from specified movies
    """
    all_subtitles = []

    print(f"Selected movies for processing:")
    for folder in selected_movies:
        print(f"- {folder}")
    print()

    # Process selected movies
    for movie_folder in selected_movies:
        movie_path = os.path.join(base_path, movie_folder)
        time_based_file = os.path.join(movie_path, 'parallel_subtitle_time_based.csv')

        if os.path.exists(time_based_file):
            try:
                # Read the CSV file
                df = pd.read_csv(time_based_file)

                # Extract language_1 column (English subtitles)
                if 'language_1' in df.columns:
                    subtitles = df['language_1'].tolist()

                    # Add movie name as metadata
                    movie_subtitles = {
                        'movie': movie_folder,
                        'subtitles': subtitles
                    }

                    all_subtitles.append(movie_subtitles)
                    print(f"Successfully processed {movie_folder}")
                else:
                    print(f"Warning: No language_1 column found in {movie_folder}")

            except Exception as e:
                print(f"Error processing {movie_folder}: {str(e)}")

    return all_subtitles

def main():
    # Configuration
    base_path = r'/content/drive/MyDrive/nlp_research/extracted_files/english to thai'
    output_file = '/content/drive/MyDrive/nlp_research/english_corpus_selected_movies.txt'
    selected_movies = [
        'Deadpool',
        'The Wolf of Wall Street',
        'Suicide Squad',
        'Bad Boys for Life',
        'Se7en',
        'Horrible Bosses',
        'The Departed',
        'The Hangover'
    ]

    # Extract subtitles
    print("Starting subtitle extraction...")
    subtitles = extract_english_subtitles(base_path, selected_movies)

    # Save to file
    if subtitles:
        save_corpus(subtitles, output_file)
        print(f"\nCorpus saved to {output_file}")

        # Print statistics
        total_movies = len(subtitles)
        total_lines = sum(len(movie['subtitles']) for movie in subtitles)
        print(f"\nStatistics:")
        print(f"Total movies processed: {total_movies}")
        print(f"Total subtitle lines: {total_lines}")
    else:
        print("No subtitles were extracted")

if __name__ == "__main__":
    main()

from transformers import BertModel, BertTokenizer
import torch.nn as nn

# Initialize the tokenizer first
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# Define the model architecture to match the pre-trained model
class EnhancedNextWordPredictor(nn.Module):
    def __init__(self, bert_model, vocab_size):
        super(EnhancedNextWordPredictor, self).__init__()
        self.bert = bert_model
        self.attention = nn.MultiheadAttention(embed_dim=bert_model.config.hidden_size, num_heads=4, batch_first=True)
        self.fc = nn.Linear(bert_model.config.hidden_size, vocab_size)

    def forward(self, input_ids, attention_mask):
        bert_output = self.bert(input_ids, attention_mask=attention_mask).last_hidden_state
        attn_output, _ = self.attention(bert_output, bert_output, bert_output)
        last_token_output = attn_output[:, -1, :]  # Use the last token's output
        logits = self.fc(last_token_output)       # Predict vocab probabilities
        return logits

# Load the pre-trained BERT model
bert_model = BertModel.from_pretrained("bert-base-uncased")
vocab_size = len(tokenizer.get_vocab())

# Initialize the EnhancedNextWordPredictor model
model = EnhancedNextWordPredictor(bert_model, vocab_size).to(device)

# Load the saved checkpoint into the model
checkpoint_path = "/content/drive/MyDrive/nlp_research/best_model.pth"
model.load_state_dict(torch.load(checkpoint_path, map_location=device))

import torch
import random
import matplotlib.pyplot as plt
from tqdm import tqdm
import os


class DQNAgent:
    def __init__(self, model, tokenizer, device, gamma=0.95, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.gamma = gamma
        self.epsilon = epsilon
        self.epsilon_min = epsilon_min
        self.epsilon_decay = epsilon_decay
        self.memory = []
        self.optimizer = Adam(model.parameters(), lr=0.001)
        self.vocab_size = len(tokenizer.get_vocab())

    def remember(self, state, action, reward, next_state, done):
        self.memory.append((state, action, reward, next_state, done))

    def act(self, state):
        if random.random() <= self.epsilon:
            return torch.randn(self.vocab_size).to(self.device)

        with torch.no_grad():
            state_input = {k: v.to(self.device) for k, v in state.items()}
            q_values = self.model(state_input['input_ids'], state_input['attention_mask'])
            return q_values

    def replay(self, batch_size):
        if len(self.memory) < batch_size:
            return 0

        minibatch = random.sample(self.memory, batch_size)
        total_loss = 0

        for state, action, reward, next_state, done in minibatch:
            target = reward
            if not done:
                next_state_input = {k: v.to(self.device) for k, v in next_state.items()}
                with torch.no_grad():
                    next_q_values = self.model(
                        next_state_input['input_ids'],
                        next_state_input['attention_mask']
                    )
                target = reward + self.gamma * torch.max(next_q_values)

            state_input = {k: v.to(self.device) for k, v in state.items()}
            current_q_values = self.model(
                state_input['input_ids'],
                state_input['attention_mask']
            )

            # Create a target tensor with the same shape as current_q_values
            target_f = current_q_values.clone()
            # Update the Q-value for the action that was taken
            action_idx = torch.argmax(action)
            target_f[0, action_idx] = target  # Add batch dimension

            self.optimizer.zero_grad()
            loss = nn.MSELoss()(current_q_values, target_f)
            loss.backward()
            self.optimizer.step()
            total_loss += loss.item()

        # Decay epsilon
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

        return total_loss / batch_size

class DynamicRewardSystem:
    def __init__(self, corpus_dataset, tokenizer):
        self.corpus_dataset = corpus_dataset
        self.tokenizer = tokenizer
        self.context_frequency = {}
        self.performance_stats = {
            'total_predictions': 0,
            'correct_predictions': 0,
            'contextual_matches': 0
        }
        self.build_context_map()

    def build_context_map(self):
        """Build frequency map of context-target pairs from corpus"""
        for context, target in self.corpus_dataset.samples:
            context_key = ' '.join(context)
            if context_key not in self.context_frequency:
                self.context_frequency[context_key] = {}
            if target not in self.context_frequency[context_key]:
                self.context_frequency[context_key][target] = 0
            self.context_frequency[context_key][target] += 1

    def get_context_score(self, context, predicted_word):
        """Calculate how well the prediction matches corpus patterns"""
        context_key = ' '.join(context)
        if context_key not in self.context_frequency:
            return 0.0

        total_occurrences = sum(self.context_frequency[context_key].values())
        word_occurrences = self.context_frequency[context_key].get(predicted_word, 0)

        return word_occurrences / total_occurrences if total_occurrences > 0 else 0.0

    def update_stats(self, is_correct, context_score):
        self.performance_stats['total_predictions'] += 1
        if is_correct:
            self.performance_stats['correct_predictions'] += 1
        if context_score > 0:
            self.performance_stats['contextual_matches'] += 1

    def get_dynamic_values(self):
        """Calculate dynamic reward/penalty values based on performance"""
        accuracy = (self.performance_stats['correct_predictions'] /
                   max(1, self.performance_stats['total_predictions']))
        context_rate = (self.performance_stats['contextual_matches'] /
                       max(1, self.performance_stats['total_predictions']))

        # Adjust base values based on performance
        target_accuracy = 0.7
        accuracy_diff = target_accuracy - accuracy

        base_reward = 10.0 * (1 + accuracy_diff * 0.2)
        base_penalty = 5.0 * (1 - accuracy_diff * 0.2)

        # Keep values in reasonable range
        base_reward = max(5.0, min(20.0, base_reward))
        base_penalty = max(2.0, min(10.0, base_penalty))

        return base_reward, base_penalty, accuracy, context_rate

class WordPredictionEnvironment:
    def __init__(self, tokenizer, corpus_dataset=None):
        self.tokenizer = tokenizer
        self.current_state = None
        self.target_word = None
        self.current_context = None
        self.episode_rewards = []
        self.corpus_dataset = corpus_dataset
        self.reward_system = DynamicRewardSystem(corpus_dataset, tokenizer) if corpus_dataset else None

        if corpus_dataset is not None:
            self.samples = corpus_dataset.samples
        else:
            self.target_words = list(tokenizer.get_vocab().keys())

    def reset(self):
        if self.corpus_dataset is not None:
            context, target = random.choice(self.samples)
            self.current_context = context
            self.target_word = target
            self.current_state = self.tokenizer(
                ' '.join(context),
                return_tensors='pt'
            )
        else:
            initial_words = random.sample(self.target_words, 2)
            self.target_word = random.choice(self.target_words)
            self.current_state = self.tokenizer(
                ' '.join(initial_words),
                return_tensors='pt'
            )
        return self.current_state

    def calculate_reward(self, predicted_word):
        # Get base token overlap score
        target_tokens = self.tokenizer(self.target_word, return_tensors='pt')
        pred_tokens = self.tokenizer(predicted_word, return_tensors='pt')

        target_set = set(target_tokens['input_ids'].squeeze().tolist())
        pred_set = set(pred_tokens['input_ids'].squeeze().tolist())
        overlap = len(target_set.intersection(pred_set))

        is_correct = (predicted_word == self.target_word)

        if self.reward_system:
            # Get corpus-based context score
            context_score = self.reward_system.get_context_score(
                self.current_context,
                predicted_word
            )

            # Update performance stats
            self.reward_system.update_stats(is_correct, context_score)

            # Get dynamic reward/penalty values
            base_reward, base_penalty, accuracy, context_rate = self.reward_system.get_dynamic_values()

            # Calculate final reward
            if is_correct:
                reward = base_reward * (1 + context_score)
            elif context_score > 0:
                reward = base_reward * context_score * 0.5  # Partial reward for contextual match
            else:
                reward = -base_penalty

            # Add length penalty
            length_diff = abs(len(predicted_word) - len(self.target_word))
            length_penalty = -0.2 * length_diff

            reward += length_penalty

            return reward, {
                'accuracy': accuracy * 100,
                'context_rate': context_rate * 100,
                'base_reward': base_reward,
                'base_penalty': base_penalty
            }
        else:
            # Fallback to basic reward calculation
            base_reward = (overlap / max(len(target_set), len(pred_set))) * 10
            if is_correct:
                base_reward += 15
            elif predicted_word in self.target_word or self.target_word in predicted_word:
                base_reward += 5

            length_diff = abs(len(predicted_word) - len(self.target_word))
            length_penalty = -0.5 * length_diff

            return base_reward + length_penalty, None

    def step(self, action):
        predicted_word = self.tokenizer.decode([torch.argmax(action).item()])
        reward, info = self.calculate_reward(predicted_word)
        self.episode_rewards.append(reward)

        current_words = self.tokenizer.decode(self.current_state['input_ids'][0])
        new_words = ' '.join(current_words.split()[1:] + [predicted_word])
        self.current_state = self.tokenizer(new_words, return_tensors='pt')

        done = True
        return self.current_state, reward, done, info

class CustomCorpusDataset:
    def __init__(self, corpus_path, tokenizer, context_size=2):
        self.tokenizer = tokenizer
        self.context_size = context_size
        self.samples = []
        self.load_corpus(corpus_path)

    def load_corpus(self, corpus_path):
        """Load and preprocess the corpus file"""
        with open(corpus_path, 'r', encoding='utf-8') as f:
            text = f.read()

        # Tokenize the text into words
        words = text.split()

        # Create context-target pairs
        for i in range(len(words) - self.context_size):
            context = words[i:i + self.context_size]
            target = words[i + self.context_size]
            self.samples.append((context, target))

def train_dqn_with_corpus(model, corpus_path, tokenizer, device,
                         episodes=1000, batch_size=32,
                         save_interval=100, save_path='dqn_checkpoints'):
    corpus_dataset = CustomCorpusDataset(corpus_path, tokenizer)
    env = WordPredictionEnvironment(tokenizer, corpus_dataset)
    agent = DQNAgent(model, tokenizer, device)

    rewards_history = []
    accuracy_history = []
    context_rate_history = []
    losses_history = []
    best_reward = float('-inf')

    os.makedirs(save_path, exist_ok=True)

    progress_bar = tqdm(range(episodes), desc='Training DQN')
    for episode in progress_bar:
        state = env.reset()
        total_reward = 0
        done = False

        while not done:
            action = agent.act(state)
            next_state, reward, done, info = env.step(action)

            agent.remember(state, action, reward, next_state, done)
            state = next_state
            total_reward += reward

        loss = agent.replay(batch_size)
        rewards_history.append(total_reward)
        losses_history.append(loss)

        if info:
            accuracy_history.append(info['accuracy'])
            context_rate_history.append(info['context_rate'])

        # Update progress bar
        progress_bar_info = {
            'Episode': episode + 1,
            'Reward': f'{total_reward:.2f}',
            'Loss': f'{loss:.4f}',
            'Epsilon': f'{agent.epsilon:.2f}'
        }
        if info:
            progress_bar_info.update({
                'Acc': f'{info["accuracy"]:.1f}%',
                'Context': f'{info["context_rate"]:.1f}%'
            })
        progress_bar.set_postfix(progress_bar_info)

        # Save best model and checkpoints
        if total_reward > best_reward:
            best_reward = total_reward
            torch.save({
                'episode': episode,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': agent.optimizer.state_dict(),
                'reward': best_reward,
                'epsilon': agent.epsilon
            }, f'{save_path}/best_model.pth')

        if (episode + 1) % save_interval == 0:
            plot_training_metrics(rewards_history, accuracy_history,
                                context_rate_history, losses_history)

    return rewards_history, accuracy_history, context_rate_history, losses_history

def plot_training_metrics(rewards, accuracies, context_rates, losses):
    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    plt.plot(rewards)
    plt.title('Rewards per Episode')
    plt.xlabel('Episode')
    plt.ylabel('Total Reward')

    if accuracies and context_rates:
        plt.subplot(2, 2, 2)
        plt.plot(accuracies, label='Accuracy')
        plt.plot(context_rates, label='Context Rate')
        plt.title('Performance Metrics')
        plt.xlabel('Episode')
        plt.ylabel('Percentage')
        plt.legend()

    plt.subplot(2, 2, 3)
    plt.plot(losses)
    plt.title('Loss per Episode')
    plt.xlabel('Episode')
    plt.ylabel('Loss')

    plt.tight_layout()
    plt.show()

rewards, accuracies, context_rates, losses = train_dqn_with_corpus(
    model=model,
    corpus_path= r"/content/drive/MyDrive/nlp_research/english_corpus_selected_movies.txt",
    tokenizer=tokenizer,
    device=device
)



